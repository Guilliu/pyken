## <b>Ejemplos de uso</b>

Los siguientes notebooks de ejemplo pretenden mostrar distintos casos de uso:
-	**01 clase autoscorecard.ipynb**
-	**02 predicciones y overfitting en titanic.ipynb**
-	**03 agrupaciones interactivas y missings.ipynb**
-	**04 descifrando scorecard.ipynb**
-	**05 inferencia de denegados.ipynb**

`En el 01` se introduce la clase **autoscorecard**, la forma m√°s autom√°tica de usar Pyken. Se genera un modelo autom√°tico con la configuraci√≥n de hiperpar√°metros por defecto utilizando un dataset de juguete de scikit-learn sobre el c√°ncer de mama.

`En el 02` se muestra c√≥mo utilizar el output de la clase autoscorecard para hacer **predicciones**. En concreto se utilizan dos datasets de Titanic de Kaggle: el original s√∫per famoso y otro menos conocido ambientado en una nave espacial donde sus tripulantes pueden cambiar o no de dimensi√≥n. Se sacan modelos autom√°ticos con la clase autoscorecard que se modifican ligeramente para reducir posibles efectos de **overfitting**. Generamos unas **submissions** que pueden subirse a Kaggle y ver en qu√© parte de la leaderboard nos situamos üòã.

`En el 03` cambiamos a otro dataset de infartos (s√≠, van todos de desgracias üòÖ) de Kaggle. Probamos a **cambiar las agrupaciones autom√°ticas de manera interactiva** en variables de distinto tipo de datos y vemos c√≥mo generar nuevas scorecards aplicando estas reagrupaciones manuales. Aprovechamos tambi√©n para explicar cu√°l es el tratamiento que hace Pyken de los valores **missings**.

`En el 04` se da un enfoque algo m√°s te√≥rico. Desengranamos, paso a paso, el **funcionamiento interno de la clase autoscorecard** utilizando para ello el dataset de juguete del ejemplo 01. Se obtienen exactamente los mismos resultados.

`En el 05` usamos un nuevo dataset donde asignamos de manera aleatoria a una submuestra del 25% la etiqueta de denegados. Mostramos como desarrollar una scorecard utilizando el **parceling** como t√©cnica de **inferencia de denegados**.

Se recomienda descargar los notebooks para visualizarlos mejor en JupyterLab o VSC (y as√≠ probar a ejecutarlos) ya que en GitHub su visualizaci√≥n es peor, sobre todo la parte de pintado de las scorecards en donde no se distingue tan bien las distintas variables involucradas.

