{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook se revela paso a paso el `funcionamiento interno` de la clase autoscorecard con el dataset del ejemplo 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Importamos los módulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, pyken as pyk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Cargamos el dataset separando las variables predictoras (guardadas en X) de la variable objetivo (guardada en y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataset tiene 569 filas y 30 columnas (sin incluir el target)\n"
     ]
    }
   ],
   "source": [
    "X, y = pd.DataFrame(load_breast_cancer().data, columns=load_breast_cancer().feature_names), load_breast_cancer().target\n",
    "print('El dataset tiene {} filas y {} columnas (sin incluir el target)'.format(X.shape[0], X.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Echamos un vistazo al dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  \n",
       "0                 0.07871  \n",
       "1                 0.05667  \n",
       "2                 0.05999  \n",
       "3                 0.09744  \n",
       "4                 0.05883  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[X.columns[:10]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Como no es buena práctica tener espacios en los nombres de las columnas mejor los sustituyo por guiones bajos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevos_nombres = [i.replace(' ', '_') for i in X.columns]\n",
    "X.columns = nuevos_nombres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Observamos que todas las variables son de tipo numérico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('float64')], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Añadimos una variable ficticia de tipo texto para tener al menos una (a ver si acaba formando parte del modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataset tiene 569 filas y 31 columnas\n"
     ]
    }
   ],
   "source": [
    "X['variable_inventada'] = ['a']*(X.shape[0]//3) + ['b']*(X.shape[0]//3) + ['c']*(X.shape[0]//3) + ['d']*(X.shape[0] - 3*(X.shape[0]//3))\n",
    "print('El dataset tiene {} filas y {} columnas'.format(X.shape[0], X.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:red'>Hasta aquí el preprocesamiento básico del dataset, que es igual al que hicimos en el notebook del ejemplo 01. Vamos ahora a desengranar como funciona autoscorecard por dentro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Lo primero que hace autoscorecard es generar una partición train-test. Por defecto hace un 70-30, estratificado en el target y con semilla 123 (para garantizar su replicabilidad por terceros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123, stratify=y)\n",
    "X_train, X_test = X_train.reset_index(drop=True), X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Después, aplica la clase `autogrouping` a todas las variables y guarda los objetos resultantes en un diccionario. Esto genera los buckets automáticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables, objetos = X_train.columns, {}\n",
    "variables_no_agrupadas = []\n",
    "\n",
    "for variable in variables:\n",
    "    \n",
    "    try:\n",
    "        x = X_train[variable].values\n",
    "        frenken = pyk.autogrouping(variable).fit(x, y_train)\n",
    "        objetos[variable] = frenken\n",
    "\n",
    "    except: variables_no_agrupadas.append(variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>También genera un DataFrame oredenado por IV. Además, no considerará a las variables que tengan un IV inverior al umbral mínimo metodológico (0.015, modificable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla_ivs, contador = pd.DataFrame(columns=['variable', 'iv']), 0\n",
    "for variable in objetos:\n",
    "    tabla_ivs.loc[contador] = variable, objetos[variable].iv\n",
    "    contador += 1\n",
    "\n",
    "tabla_ivs = tabla_ivs.sort_values('iv', ascending=False)\n",
    "variables_filtroiv = tabla_ivs[tabla_ivs['iv'] >= 0.015]['variable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_def = list(set(variables_filtroiv) - set(variables_no_agrupadas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Podemos ver cuales son las variables con mayor IV (= information value). Podríamos probar a generar una scorecard seleccionando las n primeras de mayor IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>iv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>worst_concave_points</td>\n",
       "      <td>6.377094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>worst_radius</td>\n",
       "      <td>6.169409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>worst_perimeter</td>\n",
       "      <td>6.148091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>worst_area</td>\n",
       "      <td>5.854883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mean_concave_points</td>\n",
       "      <td>5.754284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                variable        iv\n",
       "27  worst_concave_points  6.377094\n",
       "20          worst_radius  6.169409\n",
       "22       worst_perimeter  6.148091\n",
       "23            worst_area  5.854883\n",
       "7    mean_concave_points  5.754284"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabla_ivs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:red'>Por ejemplo, veamos como se haría la scorecard generada con las tres primeras variables por IV: `worst_concave_points`, `worst_radius`, `worst_perimeter`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>En *features* pondríamos las variables que queremos que formen parte de la scorecard, en este caso las tres que hemos dicho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['worst_concave_points', 'worst_radius', 'worst_perimeter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Si se quisieran usar agrupaciones manuales habría que ponerlas dentro del diccionario *user_breakpoints*, por ahora lo dejamos vacío"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_breakpoints = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>En *final_breakpoints* se actualizarían los grupos en caso de haber introducido agrupaciones manuales en user_breakpoints. Ahora se utilizaran las agrupaciones automáticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_breakpoints = pyk.compute_final_breakpoints(features, objetos, user_breakpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Antes de calcular el modelo, la clase autoscorecard aplica un *tratamiento* a las columnas del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pyk.compute_info(X_train, features, final_breakpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_adapted = pyk.adapt_data(X_train, y_train, features, final_breakpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Calculamos ya la scorecard (pero solo como *tarjeta de puntuación* en un pd.DataFrame, el objeto en sí se obtiene usando clase autoscorecard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorecard, features_length = pyk.compute_scorecard(df_train_adapted, features, info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Podemos aplicar esta tarjeta de puntuación al data de entrenamiento y ver las *métricas asociadas*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo tiene un 89.82% de KS y un 97.66% de Gini en esta muestra\n"
     ]
    }
   ],
   "source": [
    "df_train_adapted_scored, ks_train, gini_train = pyk.apply_scorecard(df_train_adapted, scorecard, info, metrics=['ks', 'gini'], print_log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Hacemos lo mismo con los datos del test (el data de validación del 30%, habitualmente también llamado *hold out*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo tiene un 92.20% de KS y un 97.63% de Gini en esta muestra\n"
     ]
    }
   ],
   "source": [
    "df_test_adapted = pyk.adapt_data(X_test, y_test, features, final_breakpoints)\n",
    "df_test_adapted_scored, ks_test, gini_test = pyk.apply_scorecard(df_test_adapted, scorecard, info, metrics=['ks', 'gini'], print_log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>No nos ha salido un mal modelo, también porque es que este dataset es MUY de juguete... La clase autoscorecard hace todo igual *salvo la selección de variables*...\n",
    "    \n",
    "<span style='color:blue'>Es decir, *no elige las variables en función de su IV sino que se utilizan cualquiera de las siguientes dos aproximaciones*:\n",
    "    \n",
    "*Método `forward` con métrica de `ks` o `gini`*: En el primer paso se parte del modelo vacío, es decir el modelo que no tiene ninguna variable. Entonces para cada variable candidata (aquellas agruapdas con un IV >= 0.015) se genera un modelo que tienen a esa variable como única variable del modelo, así de entre todos estos modelos univariable se mira cual sería el que da un mayor valor de la métrica (ks o gini) en el data del train. Aquella variable cuyo modelo de el MÁXIMO valor de la métrica se selecciona en este primer paso.\n",
    "    \n",
    "En el segundo paso se parte del conjunto que ya tiene la primera variable seleccionada del paso anterior. Ahora, se consideran TODAS las demás variables candidatas para generar TODOS los modelos de dos variables distintos posibles donde la primera es la que ya habíamos seleccionado en el paso anterior. Bien, pues de entre todos estos modelos 2-variables aquel que de el MÁXIMO valor de la métrica en el train nos indica cual es la segunda variable que seleccionamos: la que se ha añadido a la que ya teníamos para generar este modelo.\n",
    "        \n",
    "Note el lector que si el número de variables candidatas es n, entonces en el paso 1 se consideran n modelos 1-variable y en el paso 2 se considerarían (n-1) modelos 2-variables. Sin embargo, estos modelos 2-variables son más costosos desde el punto de vista computacional por tener una variable más y esto hace que los tiempos vayan aumentando en cada paso aunque el número de modelos que se consideran sea cada vez menor.\n",
    "        \n",
    "El proceso se detiene cuando se alcanza el máximo número de pasos permitidos o cuando la métrica no mejora más de un umbral (0.40 para KS y 0.25 para Gini) la del paso anterior.\n",
    "    \n",
    "*Método `stepwise` con métrica de `p-valor` (configuración por defecto de la clase autoscorecard)*: Se realiza un forward como el anteriormente descrito pero con algunas modificaciones. Se empieza buscando la variable que genera el modelo 1-variable en donde esta variable tiene el p-valor más bajo (los p-valores se calculan a nivel variable, no a nivel modelo). En un segundo paso se consideran todos los modelos 2-variables donde la primera variable es la elegida en el paso anterior y la segunda es cualquiera de las candidatas restantes. Bien, pues en cada uno de estos modelos se CALCULAN los p-valores de las dos variables y se elige el que tenga el p-valor de la variable que se está probando más bajo.\n",
    "    \n",
    "La gracia ahora es que aquí en cada paso se RECALCULAN los p-valores de TODAS las variables involucradas en el modelo de turno, no solo el de la variable candidata a entrar si no también los p-valores del resto de variables ya seleccionadas de forma que si en algún momento alguno de ellos es superior a 0.01 (nivel de significancia metodológico) entonces esta variable SALE del modelo. Esto ocurrirá cuando la variable que acaba de entrar está fuertemente correlada con la que está saliendo pero por algún motivo la que entra se combina mejor con el resto de variables del modelo y tiene una aportación 'mayor' al modelo (estadísticamente hablando).\n",
    "    \n",
    "El proceso se detiene cuando se alcanza el máximo número de pasos permitidos o cuando ninguna de las variables retadas tiene un p-valor inferior a 0.01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Hemos implementado la función `feature_selection` que replica este proceso, la usamos con sus valores por defecto para obtener el mismo set de variables que en el ejemplo 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_breakpoints = pyk.compute_final_breakpoints(variables_def, objetos, user_breakpoints)\n",
    "info = pyk.compute_info(X_train, variables_def, final_breakpoints)\n",
    "df_train_adapted = pyk.adapt_data(X_train, y_train, variables_def, final_breakpoints)\n",
    "df_test_adapted = pyk.adapt_data(X_test, y_test, variables_def, final_breakpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 01 | Time - 0:00:00.743492 | p-value = 4.93e-32 | Gini train = 83.97% | Gini test = 87.30% ---> Feature selected: mean_concavity\n",
      "Step 02 | Time - 0:00:00.946147 | p-value = 1.38e-14 | Gini train = 96.82% | Gini test = 97.24% ---> Feature selected: worst_perimeter\n",
      "Step 03 | Time - 0:00:01.132104 | p-value = 4.31e-06 | Gini train = 98.34% | Gini test = 98.07% ---> Feature selected: worst_texture\n",
      "Step 04 | Time - 0:00:01.231529 | p-value = 5.11e-04 | Gini train = 98.92% | Gini test = 97.06% ---> Feature selected: worst_smoothness\n",
      "Step 05 | Time - 0:00:01.383086 | p-value = 1.62e-03 | Gini train = 99.34% | Gini test = 98.51% ---> Feature selected: radius_error\n",
      "Step 05 | Time - 0:00:00.000000 | p-value = 1.54e-02 | Gini train = 99.25% | Gini test = 98.22% ---> Feature deleted : mean_concavity\n",
      "Step 06 | Time - 0:00:01.512500 | p-value = 2.28e-03 | Gini train = 99.60% | Gini test = 98.77% ---> Feature selected: worst_concavity\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Ya ninguna variable tiene un p-valor < 0.01, detenemos el proceso.\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Selección terminada: ['worst_perimeter', 'worst_texture', 'worst_smoothness', 'radius_error', 'worst_concavity']\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "features = pyk.features_selection(df_train_adapted, [], variables_def, info, muestra_test=df_test_adapted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Ahora ya sí la scorecard sale igual que ene ejemplo 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo tiene un 95.55% de KS y un 99.60% de Gini en esta muestra\n",
      "El modelo tiene un 95.63% de KS y un 98.77% de Gini en esta muestra\n"
     ]
    }
   ],
   "source": [
    "scorecard, features_length = pyk.compute_scorecard(df_train_adapted, features, info)\n",
    "df_train_adapted_scored, ks_train, gini_train = pyk.apply_scorecard(df_train_adapted, scorecard, info, metrics=['ks', 'gini'], print_log=True)\n",
    "df_test_adapted_scored, ks_test, gini_test = pyk.apply_scorecard(df_test_adapted, scorecard, info, metrics=['ks', 'gini'], print_log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
